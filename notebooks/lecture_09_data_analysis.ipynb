{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40ef5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CYPLAN255\n",
    "### Urban Informatics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceea7a8",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 09 -- Data Analysis\n",
    "*******\n",
    "February 14, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221723a",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/70/Eug%C3%A8ne_Delacroix_-_The_Barque_of_Dante.jpg\" width=80% title=\"The Barque of Dante, EugÃ¨ne Delacroix (1822)\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7d376",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "1. Announcements\n",
    "2. Review of last session\n",
    "3. Data Analysis\n",
    "4. For next time\n",
    "5. Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c0cef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d336f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Assignment 2 due Monday\n",
    "2. Assignment 1 will be graded soon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b61f31",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Review from Intro to Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a93919",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## 2.1 Indexing and Selecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4783c11d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- use `[<row>, <column>]` indexing with `loc` (labels) and `iloc` (positions)\n",
    "- use `df[<col>]` to select a column/Series from a DataFrame by column label\n",
    "- use `df[[<col1>, <col2>]]` to select a subset of a DataFrame by column label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368bc62c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2 Merge Methods\n",
    "\n",
    "Most of the below is taken directly from the pandas [docs](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#brief-primer-on-merge-methods-relational-algebra)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45af0e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are 4 main types of merges, but all of them require **four** arguments:\n",
    "- `left`: first `DataFrame` or `Series` to merge\n",
    "- `right`: second `DataFrame` or `Series` to merge with the first \n",
    "- `on`: the name of the \"key\" column(s) you'll use to identify matching/corresponding rows in each table\n",
    "- `how`: the type of merge to perform (default is \"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a53b90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's see how this works in practice. First we'll create some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e09938",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "left = pd.DataFrame(\n",
    "\n",
    "    {\n",
    "        \"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"],\n",
    "        \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\n",
    "        \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "        \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "    }\n",
    "\n",
    ")\n",
    "\n",
    "right = pd.DataFrame(\n",
    "    {\n",
    "        \"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"],\n",
    "        \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\n",
    "        \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "        \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106da4b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And now we'll do some merges\n",
    "\n",
    "**inner** join\n",
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_multiple.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca7931",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=[\"key1\", \"key2\"])  # inner is default \"how\", so we don't need to specify it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d322aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**left** join\n",
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_left.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047366f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, how=\"left\", on=[\"key1\", \"key2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a175a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**right** join\n",
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_right.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f241bae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(right, left, how=\"left\", on=[\"key1\", \"key2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4b6a0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**outer** (A.K.A. full) join\n",
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_outer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe044ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, how=\"outer\", on=[\"key1\", \"key2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f209cc05",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**cross** join (A.K.A. Cartesian Product)\n",
    "![](https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_cross.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70f3c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, how=\"cross\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd29dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3 Handling duplicate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecff9174",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "left = pd.DataFrame({\"A\": [4, 5], \"B\": [2, 2], \"C\": [5, 7]})\n",
    "right = pd.DataFrame({\"A\": [4, 5, 6], \"B\": [2, 2, 2], \"D\": [9, 8, 1]})\n",
    "pd.merge(left, right, on=[\"B\"], how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e6fce",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.1 Define your own suffixes!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c00fec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Keep all columns, but give them meaningful names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881400a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.merge(left, right, on=\"B\", how=\"inner\", suffixes=('_left', '_right'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ead92",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Use suffixes to drop duplicate columns after merge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f771a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, on=\"B\", how=\"inner\", suffixes=('_trash', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bcafe0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# keep only cols you want\n",
    "good_cols = [col for col in result.columns if not 'trash' in col]\n",
    "result[[\"B\", \"C\", \"A\", \"D\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef30a41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# drop cols you don't want\n",
    "trash_cols = [col for col in result.columns if 'trash' in col]\n",
    "result.drop(trash_cols, axis=1)  # \"axis\" tells pandas to drop columns (axis=1) or rows (axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c691b7aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.2 Filter out duplicate columns before you merge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fabb32",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "key = \"B\"\n",
    "left_col_mask = [\n",
    "    col for col in left.columns if (col not in right.columns) or (col == key)]\n",
    "pd.merge(left[left_col_mask], right, on=key, how=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb9afbb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Exploratory Data Analysis with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01815ca",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**READ THE DOCS**\n",
    "\n",
    "Most of the pandas-related material we saw **yesterday** corresponds to three sections of the pandas user guide:\n",
    "1. [Basics](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html)\n",
    "2. [Indexing and Selecting](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)\n",
    "3. [Merge, join, concatenate, and compare](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html)\n",
    "\n",
    "\n",
    "Most of the material we're covering **today** is also covered in the following three sections of the pandas user guide:\n",
    "1. [Group by: split-apply-combine](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)\n",
    "2. [Reshaping and pivot tables](https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html)\n",
    "3. [Chart visualization](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html)\n",
    "\n",
    "**Everything** we're covering in pandas is summarized nicely in the [10 minutes to pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html) section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ec377",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.1 The `groupby()` method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8246b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For the first part of this lesson, we're going to be analyzing some Bay Area Census data which I've already grabbed for you (specifically the Summary File 1 (SF1) data from the 2010 Census). Refer to the [SF1 Data Dictionary](https://www.census.gov/prod/cen2010/doc/sf1.pdf) to see the list of column codes. I've compiled this data into an HDF5 file, which is kind of like a .zip archive that lets you unzip one file at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa082556",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf1 = pd.read_hdf('data/bay_sf1_small.h5', 'sf1_extract')\n",
    "sf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7897d0c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note on HDF5 dependencies**\n",
    "\n",
    "pandas uses the `pytables` library to interact with .h5 files. If you don't have it installed and you try to run the cell above, Python may complain. Fear not. Did you know you can execute bash terminal commands directly from a notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13110b3e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# !conda install pytables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed74a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1.1 Basic Data Transformations\n",
    "\n",
    "In the world of machine learning, data transformation is sometimes called **feature extraction**. Both terms refer to the process of taking \"raw\" input data and manipulating it to create new, useful data. In the example below, we convert population totals to percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbb937",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf1['pct_black'] = sf1['P0030003'] / sf1['P0030001'] * 100\n",
    "sf1['pct_asian'] = sf1['P0030005'] / sf1['P0030001'] * 100\n",
    "sf1['pct_white'] = sf1['P0030002'] / sf1['P0030001'] * 100\n",
    "sf1['pct_hisp'] = sf1['P0040003'] / sf1['P0040001'] * 100\n",
    "sf1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970fa3a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now add colums with percentage rental and population per square mile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90637963",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf1['pct_rent'] = sf1['H0040004'] / sf1['H0040001'] * 100\n",
    "sf1['pop_sqmi'] = (sf1['P0010001'] / (sf1['arealand'] / 2589988))\n",
    "sf1 = sf1[sf1['P0030001'] > 0]\n",
    "sf1.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541bdea1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice how when we create new columns they get automatically appended to the end (right) of the table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650d0faf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's add county names to the dataframe so we get more readable output. First we'll create a dictionary to map the FIPS codes to county names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffb53da",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "county_fips_to_name = {\n",
    "    '001': 'Alameda', '013': 'Contra Costa', '041': 'Marin', '055': 'Napa', '075': 'San Francisco',\n",
    "    '081': 'San Mateo', '085': 'Santa Clara', '095': 'Solano', '097': 'Sonoma'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85167252",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then we pass that dictionary to the `pd.Series.replace()` method to perform the conversion.\n",
    "\n",
    "We could use the same assignment-based approach to create our new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79042f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf1['county_name'] = sf1['county'].replace(county_fips_to_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff23bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "or we can use `pd.DataFrame.insert()` to tell pandas exactly where to stick the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1bd090",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "del sf1['county_name']  # drop the column we just created\n",
    "sf1.insert(4, 'county_name', sf1['county'].replace(county_fips_to_name))\n",
    "sf1.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844ea65",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice how `insert()` operates \"in-place\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dde65a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1.2 Split-Apply-Combine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10c691",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Groupby is a powerful method in pandas that follows the split-apply-combine approach to data manipulation.\n",
    "\n",
    "<center><img src=\"https://wesmckinney.com/book/images/pda3_1001.png\" width=40%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d3d41b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**SPLIT**\n",
    "\n",
    "Let's apply this approach to computing total population in each county in our dataset. First we create a groupby object, using county codes to group all the census blocks in sf1 into groups that share the same county code. This represents the **split** part of the workflow in the figure above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf8385",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped = sf1[['P0010001', 'county_name']].groupby('county_name')\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a3a6aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**APPLY**\n",
    "\n",
    "Now were ready to apply an operation to each group we've split. We call these **aggregation** methods because for each group they will take a series of values and combine them to produce one value, like a min/max/mean. pandas provides a bunch of built-in aggregation functions for use with `groupby` object. Some of the most common ones include:\n",
    "\n",
    "* `count`\n",
    "* `sum`\n",
    "* `mean`\n",
    "* `median`\n",
    "* `std`, `var`\n",
    "* `min`, `max`\n",
    "* `idxmax`, `idxmin`\n",
    "* `first`, `last`\n",
    "* `quantile`\n",
    "\n",
    "But you can also define and apply your own functions to use for aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af9edb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**COMBINE**\n",
    "\n",
    "To apply your chosen aggregation, you can call it directly as a method of your `groupby` object. The object pandas returns will be the **combined** outputs of this method for each of your groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5577d6dd",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "grouped.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a1262",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**SPLIT-APPLY-COMBINE**\n",
    "\n",
    "Doing this in two steps like above is really just to clarify the two parts of the split and apply process that happen within a groupy operation. Normally we would not bother separately creating a groupby object -- we would just do this in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820460db",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "county_pop = sf1[['county_name', 'P0010001']].rename(\n",
    "    columns={'P0010001': 'total_pop'}).groupby(\n",
    "    'county_name').sum()\n",
    "county_pop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455639c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.2 Aggregating on multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7c53a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's merge the county totals with the original sf1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29baa1",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf2 = pd.merge(sf1, county_pop, left_on='county_name', right_index=True, how='inner')\n",
    "sf2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05622b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's say we wanted to compute the population per square mile by county.  We could go ahead and create another dataframe with total area by county than then divide the total population by total area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b448110",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "county_land = sf1[['county_name', 'arealand']].groupby(sf1['county_name']).sum()\n",
    "county_land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a8e7f5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sq_m_to_sq_mi = 2589988.11 \n",
    "county_pop['total_pop'] / county_land['arealand'] * sq_m_to_sq_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c8f68b1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Or, we could have done both aggregations at the same time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f93fc1d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf1[['county_name', 'P0010001', 'arealand']].groupby('county_name').sum()\n",
    "# county_totals['pop_density'] = county_totals['P0010001'] / county_totals['arealand'] * sq_m_to_sq_mi\n",
    "# county_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b23f687",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we want to apply different aggregations to different columns? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36fbad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sf1.groupby('county_name').agg({'pct_asian': 'mean', 'P0010001': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f04798",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "Sometimes I write `df[<list of columns>].groupby()`, but sometimes I just do `df.groupby()`. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336dfb7a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## 3.3 Exercises:\n",
    "\n",
    "Count the number of census blocks per county.\n",
    "\n",
    "Calculate total households per county.\n",
    "\n",
    "Calculate percent renters by county. (Careful not to calculate the mean percent rental across blocks in a county)\n",
    "\n",
    "Calculate percent vacant by county.\n",
    "\n",
    "Calculate mean, min and max pop_sqmi (at the block level) by county.\n",
    "\n",
    "Calculate the 90th percentile of pop_sqmi (at the block level) by county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023cb9d4",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Number of census blocks per county:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae86fba",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Total households per county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f74de19",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('percent renters by county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f9eab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Percent vacant by county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594474e1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('Min, Max and Mean Population per SQMI by Census Block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83535ab",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print('90th Percentile of Population per SQMI at block level by County')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866bdcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.4 Cleaning Messy Data -- Craigslist Rental Listings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cc2c27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.4.1 Loading data\n",
    "Let's load some rental listings I scraped from Craigslist.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acfcd9f",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bay.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603679b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It turns out to be pretty messy. What problems do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3427a5c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "- Neighborhood names are in parentheses...\n",
    "- Bedrooms and Square Feet are embedded in a single string in the bedrooms column along with other text...\n",
    "- Price is formatted as a string with a dollar sign...\n",
    "- Date is a string in a non-standard format...\n",
    "\n",
    "So how can we go about cleaning these data up to use them for analysis?\n",
    "\n",
    "Let's start with cleaning up the Price and Neighborhood variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1372b48c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.4.2 String Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7316842",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['price'] = df['price'].str.strip('$').astype('float64')\n",
    "df['neighborhood'] = df['neighborhood'].str.strip().str.strip('(').str.strip(')')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf863ada",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK, now lets create Year, Month and Day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8c8f16",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['month'] = df['date'].str.split().str[0]\n",
    "df['day'] = df['date'].str.split().str[1].astype('int32')\n",
    "df['year'] = df['date'].str.split().str[2].astype('int32')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76411b30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.4.3 Datetime ops\n",
    "\n",
    "pandas has special functions for dealing with `datetime` data types which make it much easier to do what we just did above. First we have to convert our date-like column to a `datetime` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95df894",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f78082",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we can use the `dt` method (just like `.str.` for string ops) to get month, day, year, and whatever else we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5df511",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month_name()\n",
    "df['day'] = df['date'].dt.day\n",
    "df['day_of_week'] = df['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4783c",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[['date', 'day', 'month', 'year', 'day_of_week']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8eab1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.4.4 Complex string processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8458455d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's see how we might extract the bedrooms..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d02877",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.beds_sqft.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d9aea",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_bdrm(value):\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        end = value.find('br')\n",
    "\n",
    "        if end == -1:\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            start = value.find('/') + 2\n",
    "            return int(value[start:end])\n",
    "\n",
    "    else:\n",
    "        return\n",
    "\n",
    "df['bedrooms'] = df['beds_sqft'].map(clean_bdrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e893181",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df[['bedrooms', 'beds_sqft']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5707b47",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And the same approach might work for creating a sqft column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad99fe",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def clean_sqft(value):\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        end = value.find('ft')\n",
    "        \n",
    "        if end == -1:\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            if value.find('br') == -1:\n",
    "                start = value.find('/') + 2\n",
    "            else:\n",
    "                start = value.find('-') + 2\n",
    "\n",
    "            return int(value[start:end])\n",
    "\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd414daf",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df['sqft'] = df['beds_sqft'].map(clean_sqft)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6d624",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.5 Summarizing your data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923dcae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's have a look at a statistical profile of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3703328d",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d29550",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Why are there different counts on the columns?\n",
    "- How do the price (rent) variable ranges look?  1 dollar in rent as min?  35,000 in rent as  maximum?\n",
    "- What about sqft?  1 sqft min and 12,700 sqft max?\n",
    "- You are now in the realm of real-world data, with **outliers**!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3115e8bc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.6 Dealing with outliers\n",
    "When we talk about **outliers**, we're not talking about the Malcom Gladwell kind. The kind of outliers we're talking about are the kind that are so far-fetched that they more likely represent bad data than real observations. And even if they are real, they're so amazingly rare that we don't want them to bias our analysis. In either case, we need to get rid of them.\n",
    "\n",
    "In the case of our Craigslist listings, we'll do this in three steps:\n",
    "1. Find outliers in rent, say the top and bottom 1%\n",
    "1. Analyze the data without missing data\n",
    "1. Create a dataset that removes the outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ced5457",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.6.1 Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183f2b2a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's get a quantile value at the 1st percentile to see the value that the top one percent of our records exceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d3fb83",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "low = df['price'].dropna().quantile(.01)\n",
    "print(low)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c50f675",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And now the top 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d407e2f",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "high = df['price'].dropna().quantile(.99)\n",
    "print(high)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d2618",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://static01.nyt.com/images/2021/01/26/multimedia/26xp-photog/26xp-photog-superJumbo.jpg\" width=70%></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9481592a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's apply our filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535c0166",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cleaned = df[(df['price'] < high) & (df['price'] > low)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feca7b62",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And maybe we can filter on # bedrooms, too. And why not drop rows with missing data while we're at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc287d64",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cleaned = cleaned[cleaned['bedrooms'] < 4].dropna()\n",
    "cleaned.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20412654",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.7 Continuous vs Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98cdb06",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, axarr = plt.subplots(1, 2, figsize=(13,5))\n",
    "cleaned['subregion'].value_counts(sort=False).plot(kind='bar', ax=axarr[0], title='Sub-region')\n",
    "axarr[0].set_ylabel(\"count\")\n",
    "cleaned['price'].plot(kind='kde', ax=axarr[1], title='Price ($)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231bca1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.7.1 Binning your data\n",
    "Sometimes you'll want to convert a continuous variable to categorical. pandas provides us with a few options for doing this:\n",
    "- `pd.cut()`: evenly _spaced_ bins, or define your own breaks\n",
    "- `pd.qcut()`: evenly _populated_ bins, or define your own percentile breaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52f85e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.7.1.1 `pd.cut()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e46c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.cut(cleaned['price'], 3, labels=['low', 'medium', 'high']).value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1f026",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.cut(\n",
    "    cleaned['price'], [0, 1000, 5000, 20000],\n",
    "    labels=['low', 'medium', 'high']).value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0d728",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.7.1.2 `pd.qcut()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d1e083",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "quintile_df, bins = pd.qcut(\n",
    "    cleaned['price'], 5,\n",
    "    labels=['very low', 'low', 'average', 'high', 'very high'], retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade172d3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.qcut(\n",
    "    cleaned['price'], [0, .1, .3, .7, .9, 1],\n",
    "    labels=['very low', 'low', 'medium', 'high', 'very high']).value_counts(sort=False).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb3b133",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.7.2 Dummy variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d7ff71",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Sometimes you might want to do the opposite: convert a categorical variable to a continuous or numeric variable. The way to do this is to create \"dummy variables\", where each category becomes its own _column_ with values that equal 1 if the _row_ belongs to the category and 0 otherwise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1b23f6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(cleaned['subregion']).sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ff333",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can then merge your dummy columns back onto the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5a6a80",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cleaned.join(pd.get_dummies(cleaned['bedrooms'].astype(int), prefix='beds')).loc[:, 'bedrooms':].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969609ff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.8 Putting it all together: Craigslist Rental Listings + SF1\n",
    "\n",
    "Let's load another set of rental listings. This one is a dataset I've already cleaned for you. I've also geocoded the addresses to get lat/lon coordinates and Census Block IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2d759e",
   "metadata": {},
   "source": [
    "### 3.8.1 Merging data from two different sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b14db7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals = pd.read_csv(\n",
    "    'data/sfbay_geocoded.csv',\n",
    "    usecols=['rent', 'bedrooms', 'sqft', 'fips_block', 'longitude', 'latitude'],\n",
    "    dtype={'fips_block': str}  # load fips_block as str, numeric type will drop leading zero\n",
    ")  \n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3c5174",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And merge it with the census data using the FIPS block codes, which are named differently in the two DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0256c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1 = pd.merge(rentals, sf1, left_on='fips_block', right_on='blockfips')\n",
    "rentals_sf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06d41a3",
   "metadata": {},
   "source": [
    "### 3.8.2 Multi-column group-by's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9a7d0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can begin looking at this merged dataset.  Let's start by computing mean rents by county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54a8bf6",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "county_rents = rentals_sf1.groupby(\n",
    "    rentals_sf1['county_name'])[['rent']].mean().sort_values(by='rent', ascending=False)\n",
    "county_rents.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09f905",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This result generally conforms to our expectations, with San Francisco having the highest average rent and Solano lowest. But what if Solano just has a higher percentage of 1 bedroom apartments? Could that bias our findings? How might we account for this possibility?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a390a01d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One way we could investigate the effect of total bedrooms is to include bedrooms as an additional segmentation variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2755b62d",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1.groupby(['county_name', 'bedrooms'])['rent'].mean().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988719b9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "That bar chart is not ideal. Too small, and it would be nicer to make it separate colors for each number of bedrooms.  Also notice how the use of two groupby variables produces a MultiIndex, which makes for ugly axis labels at the very least. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a49dc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can use `unstack()` to convert one of the indices from row values to columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20021cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1.groupby(['county_name', 'bedrooms'])['rent'].mean().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b8cc4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can plot a bar chart with the unstacked data, add a title, and set the figure size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844af383",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1.groupby(\n",
    "    ['county_name', 'bedrooms'])['rent'].mean().unstack().plot(\n",
    "    kind='bar', figsize=(14,6), title='Average Rents by County and # Bedrooms', ylabel='rent ($)', xlabel='county')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ef3250",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that in one line of code we can filter, groupby, and plot our results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db99825e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question:** What's wrong with the plot above? Is it really showing us what we're interested in?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c01799",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.8.3 Pivot tables and Crosstabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b4f5f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Remember when I said that in programming there is always more than one way to skin a cat? Here is another way of skinning this one that should look familiar to all of you excel power users out there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46321176",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(rentals_sf1, values='rent', index=['bedrooms'], columns=['county_name']).plot(\n",
    "    kind='bar', figsize=(14,6), title='Average Rents by County and Bedrooms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30516cff",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `pivot_table()` function makes it easy to add also can add partial totals, or \"marginals\", to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f1f5b0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(rentals_sf1, values='rent', index='county_name', columns='bedrooms', margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e600565",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Although mean is the default type of aggregation in pivot_table, you can use any aggregation method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8191f13d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(\n",
    "    rentals_sf1, values='rent', index='county_name', columns='bedrooms', aggfunc=\"count\", margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23e7fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We could use the `count` aggregation method to get a full frequency distribution, a.k.a cross-tabulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e60730e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But then again, there's an even simpler way to do this in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0b7a2c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(rentals_sf1['county_name'], rentals_sf1['bedrooms'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14aa77f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And the `crosstab()` function comes with its own bells and whistles. For example, setting `normalize=True` will tells us the fraction of the region's total listings that are in each combination of county and number of bedrooms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1268166a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(rentals_sf1['county_name'], rentals_sf1['bedrooms'], margins=True, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c43b02",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could also normalize just the rows (index) or the just the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c424f4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(rentals_sf1['county_name'], rentals_sf1['bedrooms'], margins=True, normalize='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d835bb61",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(rentals_sf1['county_name'], rentals_sf1['bedrooms'], margins=True, normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016c247e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What if we want to look at more statistics than just mean? We can combine several aggregation methods and compute them at one time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8e818",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1[rentals_sf1['bedrooms'] < 4].groupby(\n",
    "    ['county_name', 'bedrooms'])['rent'].agg(['mean', 'std', 'min', 'max']).reset_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7011d01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.8.4 Exploring correlations in your data\n",
    "\n",
    "Pandas provides simple ways of computing correlation coefficients among the columns in your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40353f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1[['rent', 'sqft']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef28a8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "And this method can be combined with groupby to compute correlation tables by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9285e7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1.groupby('county_name')[['rent', 'sqft']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed45a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.8.5 Quantiles and User-defined Aggregation Functions\n",
    "\n",
    "Below the `cut()` function to create categories for ranges of a variable. In this example we use 4 even intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe151fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sqft_cat = pd.cut(rentals_sf1['sqft'], 4)\n",
    "sqft_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50026487",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's define our own aggregation function to get a standardized maximum rent for each sqft category. Standardization is the process of transforming your data such the the mean is 0 and the standard deviation is 1, which is accomplished by subtracting the mean and dividing by the standard deviation. By standardizing your data, you are able to make more generalized comparisons across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b104cda",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rentals_sf1.groupby(sqft_cat)['rent'].agg(\n",
    "    max_rent='max', standardized_max=lambda x: (x.max() - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db0caa0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So even though the smallest apartment size category has the lowest maximum rent, it is the most _extreme_ maximum rent relative to its group mean!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48187d8c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.9 Exercises\n",
    "\n",
    "Try practicing these techniques on your own, to do the following:\n",
    "\n",
    "* Calculate the mean sqft of rental listings by county\n",
    "* Calculate the standard deviation (std) of sqft of rental listings by county and bedroom\n",
    "* Add a new column with a normalized sqft, substracting the mean sqft by bedroom from each listing's sqft \n",
    "* Compute correlation coefficients among rent, sqft, pct_white, pct_black, pct_asian and pct_hisp, by county and for the region\n",
    "* Redo the statistical profile on rents by categories of sqft range using 10 quantiles rather than 4 equal bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfb29a1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. For Next Time\n",
    "- Continue work on HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd42d62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5 Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cp255] *",
   "language": "python",
   "name": "conda-env-cp255-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
