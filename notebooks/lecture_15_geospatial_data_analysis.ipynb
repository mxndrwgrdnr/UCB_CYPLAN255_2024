{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40ef5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CYPLAN255\n",
    "### Urban Informatics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceea7a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 15 -- Geospatial Data Analysis\n",
    "******\n",
    "March 20, 2024\n",
    "\n",
    "<img src=\"https://s3-eu-west-1.amazonaws.com/ngs-mw-prod/9/97/11799/11799.jpg\" width=500 align='right' title='Alfred G Buckham, Aerial View of Edinburgh (c. 1920)'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7d376",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "1. Announcements\n",
    "2. Final projects\n",
    "3. An example\n",
    "4. More Geopandas\n",
    "5. Summary\n",
    "6. For next time\n",
    "7. Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1cb2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d336f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Final project groups [sign-up sheet](https://docs.google.com/spreadsheets/d/1aTUUA7cqtUg-5jWVrz2XrmS25SR7w-Yz6pYLzZySKOA/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a5736",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Final Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0872a1cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"../misc/final_project_description.pdf\", width=\"100%\", height=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe683b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. An example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352c11b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Historical Redlining Is Associated with Present-Day Air Pollution Disparities in U.S. Cities**[<sup id=\"fn1-back\">1</sup>](#fn1)\n",
    "\n",
    "<img src=\"https://pubs.acs.org/cms/10.1021/acs.estlett.1c01012/asset/images/large/ez1c01012_0003.jpeg\" width=700>\n",
    "\n",
    "Two open data sets:\n",
    "  - Census Block-level air pollution data available from [CACES](https://www.caces.us/data)\n",
    "  - Redlining data available from https://dsl.richmond.edu/panorama/redlining/\n",
    "\n",
    "[<sup id=\"fn1\">1</sup>](#fn1-back) Lane, H. M., Morello-Frosch, R., Marshall, J. D., & Apte, J. S. (n.d.).  Environmental Science & Technology Letters, 0(0), null. https://doi.org/10.1021/acs.estlett.1c01012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4478cde4",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"https://dsl.richmond.edu/panorama/redlining/\" width=100% height=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d22bb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question**\n",
    "\n",
    "- Correlation or causation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df40388",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- How might we inch our way towards causation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37892ac7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. More GeoPandas - Berkeley Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247cac25",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For this exercise we're going to download the Census Block geometries for the City of Berkeley:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf5829",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "blocks = gpd.read_file(\"https://data.cityofberkeley.info/api/geospatial/caxd-afre?method=export&format=Shapefile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922c0161",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "blocks.plot(color='none', edgecolor='gray', linewidth=.2, figsize=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a15f67",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.1. Our First Geoprocessing Step: Dissolve\n",
    "\n",
    "Let's say we want to create a census tract dataset from the census block one, which we can see from inspecting the data above, contains a column called tractce10, for 2010 census tracts.  We can verify it by looking more closely at the geoid10 field, which appears to be a FIPS code.\n",
    "\n",
    "Geoprocessing steps like dissolve do geometric processing on the geometry column of a GeoSeries or GeoDataFrame (which contains a GeoSeries column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50510edf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d251c0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tracts = blocks.dissolve(by='tractce10')\n",
    "tracts.plot(figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea962e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2. Setting the crs of GeoDataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82eb1d01",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's see what the crs is for the newly created dataset, and what it's type is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cf46a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(tracts.crs)\n",
    "print(type(tracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256b464",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OK, so dissolve created a new GeoDataFrame, and assigned it the same crs as the original GeoDataFrame. But just to be sure you know how to do this in the event you load a file and the crs is undefined, we will set the crs in order to do other spatial operations on the tract dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1dfe46",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts.crs = {'init' :'epsg:4326'}\n",
    "# or alternatively:\n",
    "tracts.crs = blocks.crs\n",
    "print(tracts.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edec9c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.3. Loading 311 Cases for Grafitti and Vandalism as Point Data\n",
    "\n",
    "Let's load 311 data for graffiti and vandalism, dropping rows that have missing data (a good fraction of the data seem to be missing latitude and longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98ab78e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "vandalism = pd.read_json(\"https://data.cityofberkeley.info/resource/bscu-qpbu.json?request_category=Graffiti%20and%20Vandalism&$limit=20000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb80c03",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vandalism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e05deb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We loaded a csv into a standard pandas DataFrame.  But it contains Latitude, Longitude columns, so with a couple of additional steps we can turn this into a GeoDataFrame, and set its crs.\n",
    "\n",
    "Study this example carefully. It is very common to encounter spatial data in a tabular form that you'll want to quickly turn into a geometry data types.  Note the use of the built-in `zip()` function within a list comprehension to pull the Latitude and Longitude columns together to define each Point geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2a2be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "geometry = [Point(xy) for xy in zip(vandalism.longitude, vandalism.latitude)]\n",
    "geovandalism = gpd.GeoDataFrame(vandalism, crs='epsg:4326', geometry=geometry)\n",
    "geovandalism.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3bd019",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.4. Mapping With Layers\n",
    "\n",
    "Let's see what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3bb92d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "geovandalism.plot(markersize=3);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f754e495",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A bunch of points mapped in isolation is not very informative, since it lacks context.  Let's add the points to the block base to add visual context. Note the use of Matplotlib syntax to set the parameters we want for the figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65ee9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(18,10))\n",
    "blocks.plot(color='white', edgecolor='black', linewidth=.1, ax=ax)\n",
    "geovandalism.plot(markersize=4, ax=ax)\n",
    "ax.set_title('Vandalism in Berkeley')\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227dcd94",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.5. Projecting to a Different crs\n",
    "\n",
    "So far our data has been in world coordinates (sometimes referred to as geographic cordinates). This works fine for some purposes like generating basic maps, other than the fact that the maps can appear distorted at different scales because we are squashing a spherical coordinate system onto a flat image. But there is a more fundamental issue: distances measured on a spherical coordinate system will be incorrect for point to point distance measurements we often want to do in urban data analysis.  Since we will be doing some spatial analysis on these data, we need to project them to a coordinate system that allows more meaningful measurements of distance. We'll use a standard Bay Area CRS for this purpose: EPSG:26910. You can find out more about this CRS [here](http://spatialreference.org/ref/sr-org/6787/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce228c06",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "geovandalism_proj = geovandalism.to_crs(\"epsg:26910\")\n",
    "blocks_proj = blocks.to_crs(\"epsg:26910\")\n",
    "tracts_proj = tracts.to_crs(\"epsg:26910\")\n",
    "tracts_proj.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f95159",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's check the bounds for the whole dataset to see what kind of coordinates we're working with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe68484",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bounds = tracts_proj.total_bounds\n",
    "print(bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87df9ab6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.6. Spatial Join: Intersect\n",
    "\n",
    "A very common geoprocessing operation is to do a **point-in-polygon** assignment using an intersection of the geometries of points and polygons.  It is like a normal merge, where the two datasets do not have a common key to merge on, but instead these tables have coordinates that enable geometric processing to find matching rows.\n",
    "\n",
    "GeoPandas makes this pretty easy using a spatial join, or `gpd.sjoin()` function with the `intersects` operation argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a652d8ed",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "geovandalism_proj_blocks = gpd.sjoin(geovandalism_proj, blocks_proj, how=\"inner\", op='intersects')\n",
    "geovandalism_proj_blocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5dade",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we know the Census Block ID of each record in the vandalism data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23d07e7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.7. Aggregating data using Groupby\n",
    "\n",
    "Let's say we want to look at the incidence of vandalism events at some level of geography like neighborhood or census tract rather than just looking at the raw data.  We can use groupby operations to get the counts of events within each geographic area, then merge it on to a Geodataframe to visualize it.\n",
    "\n",
    "We use a reset_index to create a unique index and make the groupby column become a column in the resulting dataframe instead of the index. That makes the merge a bit clearer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007bd33",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tract_v = geovandalism_proj_blocks.groupby('tractce10')['case_id'].count().to_frame(name='total_vandalism').reset_index()\n",
    "tract_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf8ca0e",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts2 = pd.merge(tracts_proj,tract_v, left_index=True, right_on='tractce10')\n",
    "tracts2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a00e95",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.8. Choropleth Maps\n",
    "\n",
    "One of the more obvious things you might want to do with spatial data is visualize the variations in it spatially.  Besides plotting the individual points to see their pattern, we can generate a choropleth, or thematic, map by census tract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e73e10",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts2.plot(column='total_vandalism', figsize=(14,10), legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a287bef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The default colormap is not very useful in this case. We can select a better colormap with the `cmap` param to  make our map more easily interpretable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea663516",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts2.plot(column='total_vandalism', cmap='YlGn', figsize=(14,10), legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8033e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now might be a good opportunity to spend a few minutes experimenting with different colormaps. A good place to start would be here: http://matplotlib.org/users/colormaps.html\n",
    "\n",
    "Which kinds of colormaps seem to work best for this data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12611a4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.9. The Modifiable Areal Unit Problem (MAUP)\n",
    "\n",
    "One common issue when working with geospatial data is known as the Modifiable Areal Unit Problem (MAUP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9d1091",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://mikejohnson51.github.io/spds/lec-img/15-maup.png\" width=600></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b522848",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This comes up quite frequently when working with choropleth maps, since polygons with larger areas tend to show up more prominently than might be appropriate. This happens for two reasons:\n",
    "  1. Large areas occupy more visual space on the map\n",
    "  2. Larger area == more observations \n",
    "\n",
    "We'll now investigate a few ways for dealing with these issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645ed3b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.9.1. Use Equal-Area Bins\n",
    "Perhaps the simplest approach would have been to just leave the Census Tracts out of it for the purpose of data viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624450b1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# code won't work if we have any empty geometries\n",
    "geovandalism_proj_blocks = geovandalism_proj_blocks[~geovandalism_proj_blocks.is_empty]\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "g = blocks_proj.plot(color='none', edgecolor='k', linewidth=.25, ax=ax)\n",
    "hb = ax.hexbin(x=geovandalism_proj_blocks['geometry'].x, y=geovandalism_proj_blocks['geometry'].y, gridsize=20, mincnt=1)\n",
    "fig.colorbar(hb, shrink=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ff3f8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.9.2. Normalize by Area\n",
    "\n",
    "We often want to normalize our data by area to compute a density to offset this. Geopandas gives us access to an attribute of the geometry of polygons to get the areas, so this is fairly straightforward to do.\n",
    "\n",
    "But first, check to see what units our projection is in so we can convert to a known area size, like square miles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba26207",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts2.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd949e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tracts2['area_sqmi'] = tracts2.area / 3.861e-7\n",
    "tracts2['van_sqmi'] = tracts2['total_vandalism'] / tracts2['area_sqmi']\n",
    "tracts2.plot(column='van_sqmi', cmap='OrRd', figsize=(10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d79541",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ah, that looks much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d445b7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.9.3. Interpolate!\n",
    "\n",
    "If we want to avoid aggregating the data into somewhat arbitrary geographies like census tracts, we can use 2D kernel density estimation to convert our discrete data points into a continuous surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c633cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "g = blocks_proj.plot(color='none', edgecolor='k', linewidth=.25, ax=ax)\n",
    "hb = sns.kdeplot(\n",
    "    x=geovandalism_proj_blocks['geometry'].x, y=geovandalism_proj_blocks['geometry'].y,\n",
    "    cmap='turbo', fill=True, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4a06ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The code in the next cell does essentially the same thing as the 2D KDE, but instead of estimating a continuous function it estimates a discrete 2D _histogram_ and applies a smoothing function. Code is adapted from [here](http://nbviewer.jupyter.org/gist/perrygeo/c426355e40037c452434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d25be",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "\n",
    "def heatmap(d, bins=(100,100), smoothing=1.3, cmap='turbo'):\n",
    "    def getx(pt):\n",
    "        return pt.coords[0][0]\n",
    "\n",
    "    def gety(pt):\n",
    "        return pt.coords[0][1]\n",
    "\n",
    "    x = list(d.geometry.apply(getx))\n",
    "    y = list(d.geometry.apply(gety))\n",
    "    heatmap, xedges, yedges = np.histogram2d(y, x, bins=bins)\n",
    "    extent = [yedges[0], yedges[-1], xedges[-1], xedges[0]]\n",
    "\n",
    "    logheatmap = np.log(heatmap)\n",
    "    logheatmap[np.isneginf(logheatmap)] = 0\n",
    "    logheatmap = ndimage.gaussian_filter(logheatmap, smoothing, mode='nearest')\n",
    "    blocks_proj.plot(color='none', edgecolor='white', linewidth=.5, alpha=.5, figsize=(15,10))\n",
    "\n",
    "    plt.imshow(logheatmap, cmap=cmap, extent=extent)\n",
    "    plt.colorbar(shrink=.75)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "heatmap(geovandalism_proj_blocks, bins=190, smoothing=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5499d2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Exercise: Spatial Ops with BART Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175ecb96",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bart = gpd.read_file(\"http://stacks.stanford.edu/file/druid:sp464ds6332/data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4acb74",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bart_proj = bart.to_crs(blocks_proj.crs)\n",
    "bart_berkeley = gpd.sjoin(bart_proj, blocks_proj, how=\"inner\", op='intersects')\n",
    "base = blocks_proj.plot(color='white', edgecolor='gray', linewidth=.1)\n",
    "bart_berkeley.plot(ax=base, color='green', markersize = 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3938c0b4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bart_buffer = bart_berkeley['geometry'].buffer(500)\n",
    "base = blocks_proj.plot(color='none', edgecolor='gray', linewidth=.1)\n",
    "bart_buffer.plot(ax=base, color='green', alpha=.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de26ff4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bart_buffer_df = gpd.GeoDataFrame(\n",
    "    {'geometry': bart_buffer, 'bart_buffer_df':['North \\n Berkeley','Downtown \\n Berley','Ashby']},\n",
    "    crs = blocks_proj.crs\n",
    ")\n",
    "print(bart_buffer_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0b24a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.1. Adding textual info to a map with `ax.annotate()`\n",
    "\n",
    "Below we find a **representative point** inside each BART station buffer, and use it to position a label centered inside the buffer. We'll use the Station Name as the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f287dc",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bart_buffer_df['coords'] = bart_buffer_df['geometry'].apply(lambda x: x.representative_point().coords[:])\n",
    "bart_buffer_df['coords'] = [coords[0] for coords in bart_buffer_df['coords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa59ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,10))\n",
    "base = blocks_proj.plot(color='white', edgecolor='gray', linewidth=.2, ax=ax)\n",
    "bart_buffer.plot(color='green', markersize = 5, alpha=.5, ax=ax)\n",
    "for idx, row in bart_buffer_df.iterrows():\n",
    "    ax.annotate(text=row['bart_buffer_df'], xy=row['coords'],\n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cd7a1a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.2. Spatial Overlays\n",
    "\n",
    "Spatial joins and overlays are very similar. Joins are like merges in Pandas but with GeoDataFrames, so they result in different sets being included in the resulting merge.  Spatial joins are useful for merging point and polygon layers for example, by identifying which points fall into which polygons, and then determining what to do about these relationships based on the operation requested.  \n",
    "\n",
    "We briefly talked about these last week:\n",
    "\n",
    "<center><img src=\"https://geopandas.org/en/stable/_images/overlay_operations.png\" width=700></center>\n",
    "\n",
    "Overlays are more general geoprocessing operations using set theory to produce a geometric result that contains different combinations of the inputs, and are particularly useful if you want to operate on two polygon sets or lines and polygons.\n",
    "\n",
    "We would import the relevant methods like this:\n",
    "\n",
    "```python\n",
    "from geopandas.tools import overlay\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab9880",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `geopandas.tools.overlay()` function takes three arguments:\n",
    "\n",
    "  * df1\n",
    "  * df2\n",
    "  * how\n",
    "\n",
    "Where `how` can be one of:\n",
    "\n",
    " - \"intersection\"\n",
    " - \"union\"\n",
    " - \"identity\"\n",
    " - \"symmetric_difference\"\n",
    " - \"difference\"\n",
    "\n",
    "These correspond in set theory to A & B, A or B, A, Not (A or B),  A & (Not B):\n",
    "\n",
    "| Operation    | Set Equivalent |\n",
    "|--------------|----------------|\n",
    "| Intersection | A & B |\n",
    "| Union        | A or B |\n",
    "| Identity     | A      |\n",
    "| Symmetric Difference | Not (A & B) |\n",
    "| Difference | A & (Not B) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf12941",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try these operations out on a modest size dataset (e.g. NOT parcels) so see them in action.\n",
    "\n",
    "### 5.2.1. Union\n",
    "Start with union operations.  How does the result change depending on the order of the left and right dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9ccb8",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpd.overlay(tracts_proj, bart_buffer_df, how='union').plot(figsize=(10, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6a1e37",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2.2. Identity\n",
    "OK, how about the identity operator? How does it compare to union?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc00766",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpd.overlay(tracts_proj, bart_buffer_df, how='identity').plot(figsize=(10,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a87874",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpd.overlay(bart_buffer_df, tracts_proj, how='identity').plot(figsize=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898939c3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2.3. Intersection\n",
    "And how does that result compare to intersection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd8ca1",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpd.overlay(tracts_proj, bart_buffer_df, how='intersection').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3086fb3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2.4. Symmetric Difference\n",
    "Now compare intersection to symmetric difference.  What is the relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ebcf8",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpd.overlay(tracts_proj, bart_buffer_df, how='symmetric_difference').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235eee90",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.2.5. Difference\n",
    "And finally, how does that compare to the difference operator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019093d1",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "gpd.overlay(tracts_proj, bart_buffer_df, how='difference').plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027158fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.3. Spatial Join\n",
    "\n",
    "Census Blocks and BART Station Buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ab50f9",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bart_blocks = gpd.sjoin(blocks_proj, bart_buffer_df, how=\"inner\", op='intersects')\n",
    "bart_blocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8202b",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "base = bart_blocks.plot(color='white', edgecolor='black', linewidth=.2, figsize=(10,8))\n",
    "bart_buffer_df.plot(ax=base, color='green', markersize = 5, alpha=.5)\n",
    "for idx, row in bart_buffer_df.iterrows():\n",
    "    plt.annotate(text=row['bart_buffer_df'], xy=row['coords'],\n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1453f636",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5.4. Spatial Computations\n",
    "### 5.4.1. Polygon Centroids\n",
    "\n",
    "Let's say we want to calculate distance from each census block to the nearest BART station.  If we do it with the polygon geometry of blocks it would be a very expensive calculation - we would have to check for the nearest point on the polygon, and figure out which point on each polygon is closest.  For most purposes that might be more than we need - a simple calculation fom the centroid of the parcel might serve our purposes just as well, and be much much faster to compute. So let's do that.  But wait, we don't have a set of block centroids...  fortunately that isn't hard to get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945f0d7c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "blocks_proj['centroid'] = blocks_proj.centroid\n",
    "blocks_proj = blocks_proj.set_geometry('centroid')\n",
    "print(blocks_proj.geometry.name)\n",
    "blocks_proj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c21dfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.4.2. Distance Calculations\n",
    "\n",
    "Below we use a lamda function to compute the nearest distance of each vandalism case to each of the 3 BART stations, storing the distance to the nearest BART station as a new column in the vandalism GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c5712e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "geovandalism_proj['min_dist_to_bart'] = geovandalism_proj.geometry.apply(\n",
    "    lambda g: bart_berkeley.distance(g).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b140e016",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And now we can plot the vandalism points using a color-ramp scaled by the minimum distance to a BART station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c8525",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "base = blocks_proj.set_geometry('geometry').plot(color='white', edgecolor='gray', linewidth=.1, figsize=(14,10))\n",
    "geovandalism_proj.plot(ax=base, column='min_dist_to_bart', cmap='turbo', markersize=3, legend=True)\n",
    "bart_buffer_df.plot(ax=base, color='green', markersize = 5, alpha=.5)\n",
    "for idx, row in bart_buffer_df.iterrows():\n",
    "    plt.annotate(text=row['bart_buffer_df'], xy=row['coords'],\n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6a751",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could have done this just as easily to compute the distances from each of our Census Block centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5c022",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "blocks_proj['min_dist_to_bart'] = blocks_proj.geometry.apply(lambda g: bart_berkeley.distance(g).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9713ad",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "blocks_proj.set_geometry('geometry').plot(ax=ax, column='min_dist_to_bart', cmap='turbo', marker='o', markersize=.5, alpha=.5, legend=True)\n",
    "bart_buffer_df.plot(ax=ax, color='white', edgecolor='black', markersize = 5, alpha=.75)\n",
    "for idx, row in bart_buffer_df.iterrows():\n",
    "    plt.annotate(text=row['bart_buffer_df'], xy=row['coords'],\n",
    "                 horizontalalignment='center', verticalalignment='center', fontsize=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99c98f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. Your Turn\n",
    "\n",
    "To practice with Geopandas, experiment with the methods covered so far with data you are interested in working with on your project, or any other data you can find readily from an Open Data Portal like Berkeley, San Francisco, Oakland, New York, or others.\n",
    "\n",
    "* Download a shapefile containing point data and attributes\n",
    "* Create a GeoDataFrame\n",
    "* Set its CRS\n",
    "* Plot it with color coding of the points based on the values of an attribute\n",
    "* Download a shapefile containing polygons and attributes\n",
    "* Create a GeoDataFrame\n",
    "* Plot a Choroplethic Map\n",
    "* Change the coordinate procjetion on these from spherical to a projected coordinate system\n",
    "* Do a spatial join of the point and polygon data\n",
    "* Aggregate the joined data to summarize it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbf6f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7. For next time\n",
    "- Python installs: PySAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0b2f7",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 8. Questions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd044d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sources\n",
    "\n",
    "- This notebook was heavily adapted from previous course material by [Prof. Paul Waddell](https://urbansim.com/people)."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:cp255] *",
   "language": "python",
   "name": "conda-env-cp255-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
