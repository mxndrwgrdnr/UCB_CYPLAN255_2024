{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40ef5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CYPLAN255\n",
    "### Urban Informatics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceea7a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 17 -- Making maps\n",
    "******\n",
    "April 1, 2024\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/EWZOf79X0AYkKwh?format=jpg&name=large\" width=500 align='right' title='1928 The house band for the Michelin Radio hour. c. 1928'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7d376",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "1. Announcements\n",
    "2. Static maps\n",
    "3. For next time\n",
    "4. Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1cb2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d336f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Submit your final project groups by Sunday!\n",
    "- I will be randomly assigning presentation days accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4163a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Static Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cc1783",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1373d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbacbe18",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's grab some data we've already worked with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454f3481",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "storefronts = gpd.read_file('https://github.com/dillonma/storefrontindex/raw/master/all56_nACSxMSA__41860.0.geojson')\n",
    "tracts = gpd.read_file(\"https://www2.census.gov/geo/tiger/TIGER2010/TRACT/2010/tl_2010_06_tract10.zip\")\n",
    "tracts = tracts[tracts['COUNTYFP10'].isin(['001', '013', '041', '075', '081'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c155544",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.1. GeoPandas\n",
    "\n",
    "This section should mostly be review. If you're feeling lost, refer back to the lecture 14 and 15 notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a06f842",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.1. Point Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5ea3bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "storefronts.plot(markersize=1, ax=ax, alpha=0.5)\n",
    "ax.axis('off')\n",
    "ax.set_title(\"Storefronts in the Bay Area\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30f78a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.2. Adding Data Layers\n",
    "\n",
    "The biggest single improvement we can make is probably to add in the coastline, which will give people familiar with the Bay Area a clearer sense of what they're looking at.\n",
    "\n",
    "Remember, when dealing with multiple layers of geospatial data, you'll need to make sure that the CRS's match!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033aab17",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Useful sources for background data**\n",
    "\n",
    "When you start visualizing geosptial data, all of a sudden you have to find appropriate *background* datasets to include in your maps: country borders, states, counties, etc. \n",
    "\n",
    "[Natural Earth](https://www.naturalearthdata.com), mentioned above, is a nice resource for this. So is the U.S. Census [TIGER](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html) data. That stands for Topologically Integrated Geographic Encoding and Referencing, obviously.\n",
    "\n",
    "Generally, you want to look for what's called \"cartographic\" shapefiles for this: not the administrative boundaries, which might extend out into the ocean, but the common-sense boundaries that people are most familiar with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cc540",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "outlines = gpd.read_file('https://www2.census.gov/geo/tiger/GENZ2016/shp/cb_2016_us_state_500k.zip')\n",
    "outlines = outlines[outlines['GEOID'] == '06']  # just CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f242f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2831bd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "outlines.plot(ax=ax, facecolor='none')\n",
    "storefronts.to_crs(outlines.crs).plot(alpha=0.5, markersize=1, ax=ax, marker='.')\n",
    "ax.set_title(\"Storefronts in the Bay Area\")\n",
    "\n",
    "buff = .2\n",
    "ax.set_xlim(storefronts['geometry'].x.min() - buff, storefronts['geometry'].x.max() + buff)\n",
    "ax.set_ylim(storefronts['geometry'].y.min() - buff, storefronts['geometry'].y.max() + buff)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd806a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.3. Basic Choropleth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d11ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "storefronts.index.name = 'storefront_id'\n",
    "storefronts.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e04aa4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts_w_stores = gpd.sjoin(storefronts, tracts.to_crs(storefronts.crs), how='inner', predicate='within')\n",
    "tract_counts = tracts_w_stores.groupby('GEOID10')['storefront_id'].count().reset_index()\n",
    "tracts = pd.merge(tracts, tract_counts, on='GEOID10', how='left')\n",
    "tracts['store_count'] = tracts['storefront_id'].fillna(0)\n",
    "tracts = tracts.clip(outlines.to_crs(tracts.crs))  # clip tract geoms to coastline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d0979",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "tracts.plot(\n",
    "    column='store_count',\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    antialiased=False\n",
    "    \n",
    ")\n",
    "outlines.plot(ax=ax, facecolor='none')\n",
    "ax.set_title(\"Storefronts in the Bay Area\")\n",
    "\n",
    "buff = .1\n",
    "ax.set_xlim(storefronts['geometry'].x.min() - buff, storefronts['geometry'].x.max() + buff)\n",
    "ax.set_ylim(storefronts['geometry'].y.min() - buff, storefronts['geometry'].y.max() + buff)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c583bdd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.3. Normalize by Unit Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52033b4b",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "tracts['store_density'] = tracts['store_count'] / tracts['ALAND10']\n",
    "\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"4%\", pad=0.05)\n",
    "\n",
    "tracts.plot(\n",
    "    column='store_density',\n",
    "    edgecolor='none',\n",
    "    ax=ax,\n",
    "    cax=cax, \n",
    "    legend=True,\n",
    "    legend_kwds={'label': 'Density'},\n",
    "    antialiased=False\n",
    ")\n",
    "outlines.plot(ax=ax, facecolor='none', )\n",
    "ax.set_title(\"Storefronts in the Bay Area\")\n",
    "\n",
    "buff = .1\n",
    "ax.set_xlim(storefronts['geometry'].x.min() - buff, storefronts['geometry'].x.max() + buff)\n",
    "ax.set_ylim(storefronts['geometry'].y.min() - buff, storefronts['geometry'].y.max() + buff)\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de400cfd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1.4. Alternative Classification Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b81369",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "tracts.plot(\n",
    "    column='store_density',\n",
    "    edgecolor='none',\n",
    "    lw=.01,\n",
    "    ax=ax,\n",
    "    k=10,  # number of bins\n",
    "    scheme='quantiles',  # choropleth classification scheme\n",
    "    legend=True,\n",
    "    legend_kwds={\n",
    "        'title': 'Density Deciles',\n",
    "        'loc':'lower left',\n",
    "        'labels': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "    },\n",
    "    antialiased=False  # turn off \n",
    "\n",
    ")\n",
    "outlines.plot(ax=ax, facecolor='none', edgecolor='white')\n",
    "ax.set_title(\"Storefronts in the Bay Area\", fontsize=15)\n",
    "\n",
    "buff = .1\n",
    "ax.set_xlim(storefronts['geometry'].x.min() - buff, storefronts['geometry'].x.max() - buff)\n",
    "ax.set_ylim(storefronts['geometry'].y.min() - buff, storefronts['geometry'].y.max() + buff)\n",
    "ax.set_facecolor('k')\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3aa94f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises\n",
    "Geopandas uses a library called `mapclassify` to implement the choropleth classification schemes. Check out the documentation here for all of the available options: https://pysal.org/mapclassify/api.html\n",
    "1. Try implementing two different classifaction schemes. \n",
    "2. Try using quantiles to visualize the original storefront counts (not densities). How does it compare to the density quantiles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef43fae",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bae77beb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2. Map tiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd2bcf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You are probably a lot more familiar with **map tiles** than you think. If you have ever used Google Maps, Apple Maps, Bing Maps, OpenStreetMap, you have used map tiles. Broadly speaking, map tiles are how interactive maps get rendered on the web. It's the technology that lets you quickly pan and zoom around a map without the images appearing blurry at high zoom levels, or overcrowded at low zoom levels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2798e9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For two great overviews of map tiles, how they work, and how they enable pretty much ever web map you've ever seen, check out these two blog posts:\n",
    " - http://www.liedman.net/tiled-maps/\n",
    " - https://www.axismaps.com/guide/what-is-a-web-map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3783d3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Map tiles are in essence nothing more than a very efficient data structure for dividing a map data/imagery into a hierarchical grid. Tiles have become the industry standard for web mapping because they allow your browser to query, download, and render only the portion of the map/data you need at the moment you need it. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a012973",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|<center> Zoom Level 2</center>| <center>Zoom Level 3</center>|\n",
    "|---|---|\n",
    "|![](https://uploads-ssl.webflow.com/5f6a4786fa53db61032919f9/5fa45554fb44c1d15e3c7945_zoom2.jpeg)|![](https://uploads-ssl.webflow.com/5f6a4786fa53db61032919f9/5fa45554e24ff53ccf08c7ad_zoom3.jpeg)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32480455",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The entire goal of this is to make web maps feel as smooth and responsive as possible when you interact with them, so that they almost feel _animated_. But this is just an illusion. It is all static imagery being intellegently and dynamically rendered.\n",
    "\n",
    "This means map tile data can be used just as easily for static maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e1c3a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2.1. Static map tile basemaps with `contextily`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132d94fc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Contextily is a super useful, super simple library from the PySAL folks for dynamically generating static basemaps for your `matplotlib` plots. It's really as simple as adding a single line of code to the plots we've already been making. All you have to do is pass the `pyplot` axes object to `cx.add_basemap()`, along with the CRS of the dataset you're plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d12a0f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "storefronts.plot(markersize=1, ax=ax, alpha=0.5)\n",
    "ax.axis('off')\n",
    "ax.set_title(\"Storefronts in the Bay Area\", fontsize=15)\n",
    "cx.add_basemap(\n",
    "    ax,\n",
    "    crs=storefronts.crs.to_string(),\n",
    "    source=cx.providers.CartoDB.PositronNoLabels,\n",
    "    zoom=10\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6733f3a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the code above, the `source=` argument of `cx.add_basemap()` let's you choose from a number of different map tile providers. Check out the documentation [here](https://contextily.readthedocs.io/en/latest/intro_guide.html#Providers) to see all of the available options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee81bef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2893016",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Play around with different combinations of matplotlib marker styles (color, shape, opacity) and basemap styles until you find the one you think is best. Does the basemap provide useful context than the coast line shapefile we used before? Or does it add visual noise?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc10ead",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23fa3d7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.3. Custom choropleth geometries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8229019e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In Section 2 above, we used a density metric to avoid the effect of the modifiable areal unit problem in our Census Tract map of storefront counts. As we've seen before, an alternative approach is to define your own equal-area geometries. For simple count data, this is usually the preferred method, since administrative boundaries don't really provide useful context anyways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47ba4ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.1 GeoPandas + Matplotlib Hexbins\n",
    "\n",
    "This code illustrates how you can mix-and-match map shapes with other kinds of data visualizations and annotations in Matplotlib. It can take a while to work out all the syntax to accomplish things like this, but it's quite powerful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910c7fbd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "First we'll need to pull latitude and longitude out into normal DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8ec9d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "storefronts['lon'] = storefronts.geometry.x\n",
    "storefronts['lat'] = storefronts.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc1886",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "# Plot coastline using GeoPandas\n",
    "outlines.plot(ax=ax, color='whitesmoke', edgecolor='black')\n",
    "\n",
    "# Plot hexbins of storefronts using Matplotlib\n",
    "hb = plt.hexbin(storefronts.lon, storefronts.lat, mincnt=1, gridsize=50, alpha=.8, lw=0)\n",
    "\n",
    "# Add a key\n",
    "cb = fig.colorbar(hb, ax=ax)\n",
    "cb.set_label('Count')\n",
    "\n",
    "# Title and bounds\n",
    "ax.set_title('Storefronts in the Bay Area')\n",
    "ax.set_xlim((-122.7, -121.9))\n",
    "ax.set_ylim((37.4, 38.15))\n",
    "\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cad89b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.2. Custom hexbins with `h3` and `tobler`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fb754",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`h3` is an open-source hexagonal geospatial index developed by a ridehailing company. Together, the hexagons define hierarchical **discrete global grid**, meaning it covers the surface of the earth, with no gaps, at multiple levels of resolution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8176b2",
   "metadata": {},
   "source": [
    "<img src=\"https://blog.uber-cdn.com/cdn-cgi/image/width=2160,quality=80,onerror=redirect,format=auto/wp-content/uploads/2018/06/Twitter-H3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1810aa9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`h3py` is the official Python binding for using `h3` in Python, which you can find here: https://github.com/uber/h3-py. For this exercise, we're going to use a library called `tobler` instead, but you'll still need to install the underling `h3py` package (`pip install h3`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b11ed",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`tobler` is another great library from the `PySAL` folks which let's us easily extract h3 geometries using a GeoPandas `GeoDataFrame` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104e8ce6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from tobler.util import h3fy\n",
    "from tobler.area_weighted import area_interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d69165",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tracts_proj = tracts.to_crs('epsg:26910')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae4dc3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hexes = h3fy(tracts_proj.to_crs('epsg:4326'), resolution=7, clip=True).to_crs(\"epsg:26910\")\n",
    "print(type(hexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fb0ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2, figsize=(18,10))\n",
    "axs=axs.flatten()\n",
    "\n",
    "tracts_proj.plot(ax=axs[0], alpha=0.4, linewidth=1, edgecolor='white')\n",
    "hexes.plot(ax=axs[1], alpha=0.4, linewidth=1, edgecolor='white')\n",
    "\n",
    "axs[0].set_title('Original Tract Data')\n",
    "axs[1].set_title('Hex Grid')\n",
    "\n",
    "for i,_ in enumerate(axs):\n",
    "    cx.add_basemap(\n",
    "        axs[i],\n",
    "        crs=hexes.crs.to_string(),\n",
    "        source=cx.providers.CartoDB.PositronNoLabels)\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993f140",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we can use the same code we used to the tract count map, but with the hexes as our aggregation geometries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e37d86",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "hexes = hexes.reset_index()\n",
    "hexes_w_stores = gpd.sjoin(storefronts, hexes.to_crs(storefronts.crs), how='inner', predicate='within')\n",
    "hexes_counts = hexes_w_stores.groupby('hex_id')['storefront_id'].count().reset_index()\n",
    "hexes = pd.merge(hexes, hexes_counts, on='hex_id', how='left')\n",
    "hexes['store_count'] = hexes['storefront_id'].fillna(0)\n",
    "hexes = hexes.clip(outlines.to_crs(hexes.crs))  # clip tract geoms to coastline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6169c66",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "hexes[hexes['store_count'] > 0].plot(\n",
    "    column='store_count',\n",
    "    ax=ax,\n",
    "    legend=True,\n",
    "    scheme='naturalbreaks',\n",
    "    alpha=0.8    \n",
    ")\n",
    "\n",
    "cx.add_basemap(\n",
    "    ax,\n",
    "    crs=hexes.crs.to_string(),\n",
    "    source=cx.providers.CartoDB.DarkMatter)\n",
    "ax.set_title(\"Storefronts in the Bay Area\", fontsize=15, pad=30)\n",
    "\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f3e985",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Try experimenting with different `h3` resolutions and classification schemes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8980217",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "418fa1ad",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3.3. Areal Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb8985",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As we've seen, there are many advantages to using exogenously defined, arbitrary geometries to display geospatial data. By aggregating point data to equal-area bins, we can avoid the visual biases imposed by both the plotting of raw points (overlapping, crowded geometries) and administrative boundaries (e.g. MAUP). It is also super straightforward to assign points to polygons, as it will almost always be a one-to-one relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd1116",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "But what about non-point-based data? What if you are using Census data, which is only reported for administrative geometries like Census Tracts and Blocks? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56d8f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This would require some kind of mapping of hexbins to administrative boundaries, or vice versa. This can be tricky to do, as it is highly unlikely that the mappings will be one-to-one. More likely, the administrative boundaries will be split across reference geometries, or contain multiple reference geometries, depending on their relative sizes. Additionally, the result might change depending on the kind of spatial join you use to perform the operation (e.g. `contains`, `within`, `touches`, `overlaps`, etc.). The use case for hexbins here is less obvious, but let's go with it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5c607",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The simplest approach would probably to do an `intersects` operation, but this might return multiple hexbins for each administrative boundary. In this case, you might consider simpling mapping each administrative boundary to the hexbin with which it has the highest degree of overlap.The result might look something like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9bc24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/hex1.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623f4cb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/hex2.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178cb2cc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/hex3.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e512c56",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"images/hex4.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9594b45",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These images might be nice to look at, but they also highlight how messy it can be to map polygons to one another. You'll also still need to aggregate the data from the administrative zones to the hexbins, and clearly some of these aggregations will contain more error than others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d60ed81",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A more rigorous approach would also involve computing the degree of overlap between polygons, but then using that overlap to allocate the data proportionally from the administrative boundaries to the hexbins. Essentially slicing your data up. You can imagine how you might due this using a `union` overlay operation, and then performing an aggregation by hexbin using a weighted mean with weights defined by the area of smaller geometries. Sounds like a lot of work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d0bf8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fortunately, `tobler` has you covered. For this example we're going to pretend that we didn't have the original point data, but only the storefront density metric for each Census Tract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168cc1b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "metric = 'store_density'\n",
    "hex_interpolated = area_interpolate(\n",
    "    source_df=tracts_proj, target_df=hexes, intensive_variables=[metric])\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(16, 8))\n",
    "\n",
    "tracts_proj.plot(\n",
    "    metric, scheme='fisherjenks', alpha=0.8, ax=axs[0], edgecolor='none', antialiased=False)\n",
    "hex_interpolated.plot(\n",
    "    metric, scheme='fisherjenks', alpha=0.8, ax=axs[1], edgecolor='none', antialiased=False)\n",
    "\n",
    "axs[0].set_title('Original Data')\n",
    "axs[1].set_title('Interpolated Data')\n",
    "           \n",
    "for ax in axs:\n",
    "    cx.add_basemap(\n",
    "        ax=ax,\n",
    "        source=cx.providers.CartoDB.Positron,\n",
    "        crs=hexes.crs.to_string())\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.suptitle('Spatial Interpolation with the PySAL $\\mathtt{tobler}$ package', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d63e895",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we're interpolating the value of the density metric rather than the point counts. Why might it be a bad idea to interpolate the point counts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de2c8bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For more examples of interpolation, and different interpolation methods, check out the `tobler` documentation [here](https://pysal.org/tobler/notebooks/01_interpolation_methods_overview.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ad161",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.4. Dot-density maps -- alternative to choropleth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c69c333",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A useful alternative to the choropleth map which avoids both MAUP and aggregation bias is the dot-density map. These became very popular around the time of the 2010 Decennial Census due to a racial dot density map of Chicago made by Professor Bill Rankin (a.k.a. [Radical Cartography](http://www.radicalcartography.net/index.html?chicagodots))\n",
    "\n",
    "<center><img src=\"http://www.radicalcartography.net/chicagodots_race_lines.jpg\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e81a402",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Some other really fascinating examples followed from the [Cooper Center](https://demographics.coopercenter.org/racial-dot-map) at the University of Virginia, and Bay Area cartographer [Erica Fischer](https://commons.wikimedia.org/wiki/Category:Race_and_Ethnicity_by_Eric_Fischer_(2010_Census_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312c6e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Detroit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859696ec",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<center><img src=\"https://www.gannett-cdn.com/-mm-/c1fd377bdd190832b44b31a5c9345a838610929b/c=0-2-1489-843/local/-/media/2015/09/01/DetroitFreePress/DetroitFreePress/635767091539964541-race.JPG\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824edb7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To find out more about dot-density maps, what they do well and what they do not-so-well, check out the ever-useful Axis Maps cartography guide [here](https://www.axismaps.com/guide/dot-density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5795a4a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise:\n",
    "\n",
    "Rather than re-create the wheel, check out [this](https://web.archive.org/web/20220107205957/http://andrewgaidus.com/Dot_Density_County_Maps/) step-by-step guide for creating dot density maps in Python. Copy-paste that code into this notebook and try to create your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e6f0b5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. For next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599cdc03",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. Questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b0e50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cp255] *",
   "language": "python",
   "name": "conda-env-cp255-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
